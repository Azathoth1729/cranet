{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cranet\n",
    "from cranet import nn, optim\n",
    "from cranet.nn import functional as F\n",
    "from cranet.util import load_pickle\n",
    "from cranet.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "print(cranet.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistDataset(Dataset):\n",
    "    train_img = 'train-images-idx3-ubyte'\n",
    "    train_lab = 'train-labels-idx1-ubyte'\n",
    "    test_img = 't10k-images-idx3-ubyte'\n",
    "    test_lab = 't10k-labels-idx1-ubyte'\n",
    "\n",
    "    def __init__(self, root, mode, transform=None, transform_target=None):\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "        self.transform_target = transform_target\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        self._load_data(os.path.join(root, 'MNIST', 'raw'))\n",
    "\n",
    "    def _load_data(self, data_dir):\n",
    "        if self.mode == 'train':\n",
    "            image_file = os.path.join(data_dir, self.train_img)\n",
    "            label_file = os.path.join(data_dir, self.train_lab)\n",
    "        elif self.mode == 'test':\n",
    "            image_file = os.path.join(data_dir, self.test_img)\n",
    "            label_file = os.path.join(data_dir, self.test_lab)\n",
    "        else:\n",
    "            raise RuntimeError('mode must be train or test')\n",
    "\n",
    "        with open(image_file, 'rb') as f:\n",
    "            f.read(4)  # magic\n",
    "            self.size = int.from_bytes(f.read(4), \"big\")\n",
    "            r = int.from_bytes(f.read(4), \"big\")\n",
    "            c = int.from_bytes(f.read(4), \"big\")\n",
    "            for _ in range(self.size):\n",
    "                mat = []\n",
    "                for i in range(r):\n",
    "                    mat.append([])\n",
    "                    for j in range(c):\n",
    "                        mat[i].append(int.from_bytes(f.read(1), \"big\"))\n",
    "                self.images.append(np.array(mat))\n",
    "\n",
    "        with open(label_file, 'rb') as f:\n",
    "            f.read(4)  # magic\n",
    "            sz = int.from_bytes(f.read(4), \"big\")  # size\n",
    "            assert self.size == sz\n",
    "            for _ in range(self.size):\n",
    "                lab = np.array(int.from_bytes(f.read(1), \"big\"))\n",
    "                self.labels.append(lab)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]\n",
    "        lab = self.labels[idx]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        if self.transform_target is not None:\n",
    "            lab = self.transform_target(lab)\n",
    "\n",
    "        return img, lab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(img):\n",
    "    return img.reshape(1, 28, 28) / 256\n",
    "\n",
    "\n",
    "def transform_target(lab):\n",
    "    return np.array([lab])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans(x):\n",
    "    x = x.reshape(1, 28, 28)\n",
    "    return cranet.as_tensor(x)\n",
    "\n",
    "\n",
    "def trans_lab(x):\n",
    "    return cranet.as_tensor(x)\n",
    "\n",
    "\n",
    "train_ds = MnistDataset('data', 'train', trans, trans_lab)\n",
    "test_ds = MnistDataset('data', 'test', trans, trans_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ld = DataLoader(train_ds, 64)\n",
    "test_ld = DataLoader(test_ds, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image_batch, sample_label_batch = next(iter(train_ld))\n",
    "sample_image = sample_image_batch.numpy()[0]\n",
    "sample_label = sample_label_batch.numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sample_image.reshape(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(4608, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optm = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (inp, lab) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(inp)\n",
    "        loss = F.nll_loss(out, lab)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_v = loss.item()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * 64, len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss_v))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, loader, label=''):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    with cranet.no_grad():\n",
    "        for inp, lab in loader:\n",
    "            out = model(inp)\n",
    "            loss += F.nll_loss(out, lab, reduction='sum').item()\n",
    "            pre = out.numpy().argmax(axis=1)\n",
    "            correct += (pre == lab.numpy()).sum().item()\n",
    "\n",
    "    data_size = len(loader.dataset)\n",
    "    loss /= data_size\n",
    "    accu = correct / data_size\n",
    "    print('\\n{} set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        label, loss, correct, data_size, accu*100.))\n",
    "\n",
    "    return accu, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "train_accu = []\n",
    "test_loss = []\n",
    "test_accu = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    train(model, train_ld, optm, epoch)\n",
    "    accu, loss = test(model, train_ld, 'Train')\n",
    "    train_loss.append(loss)\n",
    "    train_accu.append(accu)\n",
    "    accu, loss = test(model, test_ld, 'Test')\n",
    "    test_loss.append(loss)\n",
    "    test_accu.append(accu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title('loss')\n",
    "plt.plot(train_loss, label='train loss')\n",
    "plt.plot(test_loss, label='test loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"accuracy\")\n",
    "plt.plot(train_accu, label='train_accu')\n",
    "plt.plot(test_accu, label='test_accu')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, loader):\n",
    "    pre_arr = []\n",
    "    tar_arr = []\n",
    "    for inp, tar in loader:\n",
    "        out = model(inp)\n",
    "        pre = out.numpy().argmax(axis=1)\n",
    "        pre_arr.append(pre)\n",
    "        tar_arr.append(tar.numpy())\n",
    "    pre_arr = np.concatenate(pre_arr)\n",
    "    tar_arr = np.concatenate(tar_arr)\n",
    "    return confusion_matrix(tar_arr, pre_arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = eval(model, test_ld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "    \"\"\"\n",
    "    given a sklearn confusion matrix (cm), make a nice plot\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
    "\n",
    "    target_names: given classification classes such as [0, 1, 2]\n",
    "                  the class names, for example: ['high', 'medium', 'low']\n",
    "\n",
    "    title:        the text to display at the top of the matrix\n",
    "\n",
    "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
    "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                  plt.get_cmap('jet') or plt.cm.Blues\n",
    "\n",
    "    normalize:    If False, plot the raw numbers\n",
    "                  If True, plot the proportions\n",
    "\n",
    "    Usage\n",
    "    -----\n",
    "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
    "                                                              # sklearn.metrics.confusion_matrix\n",
    "                          normalize    = True,                # show proportions\n",
    "                          target_names = y_labels_vals,       # list of names of the classes\n",
    "                          title        = best_estimator_name) # title of graph\n",
    "\n",
    "    Citiation\n",
    "    ---------\n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "    \"\"\"\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(\n",
    "        accuracy, misclass))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm, [0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b89d7100bc25b91e21f760c78c1c5d4e44459f90518fd170ba80cad75240bc7f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('py3.9': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
